---
title: "Análise da precisão"
output: html_notebook
---

```{r}
library(tidyverse)
library(here)
library(modelr)
library(broom)
library(GGally)

theme_set(theme_bw())
```

## Os dados

```{r carrega}

reclamacoes = read_csv(here("data/3-avaliacao-humana/reclamacoes-avaliadas-20180703.csv"))
sentimentos = read_csv(here("data/4-estimativa-automatica/sentimento.csv"))

reclamacoes = reclamacoes %>% mutate(comprimento_reclamacao = str_length(reclamacao),
                                     palavras.caps = str_count(reclamacao, "[A-Z]{2,}"))
```

`reclamacoes_l` tem um formato long em vez de wide (explicado [aqui](https://sejdemyr.github.io/r-tutorials/basics/wide-and-long/)).

```{r junta}
reclamacoes = reclamacoes %>% 
    left_join(sentimentos, by = "id")

reclamacoes_l = reclamacoes %>%  
    select(-palavras_op30, -palavras_sent, -grupo_avaliando) %>% 
    gather(key = "lexico", 
           value = "polaridade", 
           sentimento_op30, sentimento_sent)

reclamacoes_l %>% View()

```

Converte polaridades para escala 0-5

```{r}
# Faça você mesmo. Crie a variável polaridade_normalizada
reclamacoes_l = reclamacoes_l %>% 
    group_by(lexico) %>% 
    mutate(polaridade_normalizada = round(((4 * (polaridade - max(polaridade))) / (min(polaridade) - max(polaridade))) + 1))
```

Calcula o erro (SSE) por reclamação

```{r}
reclamacoes_l = reclamacoes_l %>% 
    mutate(erro = (insatisfacao - polaridade_normalizada)**2)
```


## EDA

Inicial. Faça os gráficos a mais que achar necessário para entender os dados que temos de resultado. Lembrando de nossa questão: Quão eficazes são os métodos de análise de sentimento baseados em léxicos para estimar o nível de insatisfação de reclamações recebidas pelo reclameaqui do governo federal? Existe um exemplo de EDA no repositório. Uma decisão importante a ser usada é se vamos considerar as avaliações humanas onde houve muita discordância sobre o nível de insatisfação.

###Como avaliar a eficácia dos métodos?  
Uma medida interessante da eficiência desses métodos é calcular a soma dos erros ao quadrado (SSE) considerando o que o método definiu como a polaridade_normalizada e o que a avaliação humana definiu como a insatisfação.

```{r}
reclamacoes %>% 
    ggplot(aes(x = sentimento_op30, y = sentimento_sent)) + 
    geom_abline(slope = 1, intercept = 0, color = "grey") + 
    geom_count(alpha = .7) 
```

```{r}
reclamacoes_l %>% 
    ggplot(aes(x = insatisfacao, y = polaridade_normalizada, group = insatisfacao)) + 
    geom_abline(slope = 1, intercept = 0, color = "grey") + 
    geom_jitter(alpha = .7)  + 
    facet_wrap(~ lexico)

reclamacoes_l %>% 
    ggplot(aes(x = insatisfacao, y = erro, group = insatisfacao)) + 
    geom_jitter(alpha = .5)  +
    # geom_boxplot() + 
    facet_wrap(~ lexico)
```


## Há relação entre o léxico e o erro?

Agora um modelo para responder sua pergunta.

```{r}
#Cria variável dummy para preditor categórico
reclamacoes_l = reclamacoes_l %>% mutate(lexico.dummy = if_else(lexico == "sentimento_sent", 1, 0))
reclamacoes_l = reclamacoes_l %>% mutate(orgao.dummy = if_else(orgao == "anac-agencia-nacional-de-aviacao-civil", 1, 0))
#Você precisa entender o que fez acima para interpretar sua regressão
#Você pode também criar uma variável dummy para o órgao (se anac ou inss)

ggpairs(reclamacoes_l %>% select(insatisfacao, avaliadores, range.avaliacoes, comprimento_reclamacao, palavras, polaridade_normalizada, erro, lexico.dummy, orgao.dummy))
lm1 = lm(erro ~ lexico.dummy, data = reclamacoes_l)
summary(lm1)
tidy(lm1, conf.int = TRUE, conf.level = 0.95)
```

```{r}
#to do: nao. nao ha relacao entre o lexico e o erro, pq o lexico nao eh um bom preditor pro erro, pq tem o 0 no seu IC, o r² eh muito baixo, e o p valor eh maior que 0.5.

# Ambos os léxicos são eficientes para avaliar a insatisfação
```


Utilizamos regressão simples para analisar se o léxico tem uma associação significativa com o erro na estimação de insatisfação da reclamação. O modelo utilizado, `erro = 2.2000 - 0.1333 * lexico`, utilizando o léxico como variável preditora medida em 1 para o léxico *sent* e 0 para o *op_30*, com 95% de confiança, mostrou que o léxico não influencia no erro, pois possui o zero em seu intervalo de confiança (léxico = []) # to do

**Dica** - o texto de resultado que queremos produzir é algo como: 

Regressão múltipla foi utilizada para analisar se VarIndep1 e VarIndep2 tem uma associação significativa com o erro na estimativa de instatisfação da reclemação. Os resultados da regressão indicam que um modelo com os 2 preditores no formato Erro = XXX.VarIndep1 + YYY.VarIndep2 explicam XX,XX% da variância da variável de resposta (R2 = XX,XX). VarIndep1, medida como/em [unidade ou o que é o 0 e o que é 1] tem uma relação significativa com o erro (b = [yy,yy;  zz,zz], IC com 95%), assim como VarIndep2 medida como [unidade ou o que é o 0 e o que é 1] (b = [yy,yy;  zz,zz], IC com 95%). O aumento de 1 unidade de VarIndep1 produz uma mudança de...


```{r}
lm2 = lm(polaridade_normalizada ~ palavras + palavras.caps, reclamacoes_l)
summary(lm2)
tidy(lm2, conf.int = TRUE, conf.level = 0.95)

lm3 = lm(insatisfacao ~ palavras + palavras.caps, reclamacoes_l)
summary(lm3)
tidy(lm3, conf.int = TRUE, conf.level = 0.95)

```

Na primeira regressão as variáveis utilizadas não são preditoras da polaridade_normalizada, mas, na segunda regressão, observamos que as variaveis sao boas preditoras para a avaliacao humana.
Aqui, podemos concluir que isso acontece porque os léxicos não levam em consideração essas variáveis, mas aparentemente essas características foram importantes no nivelamente da insatisfação avaliada por humanos.


```

